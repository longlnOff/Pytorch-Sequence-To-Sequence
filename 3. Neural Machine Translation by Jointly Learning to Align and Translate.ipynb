{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Neural Machine Translation by Jointly Learning to Align and Translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ở notebook thứ 3 này, chúng ta sẽ cùng implementing model từ paper [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf). Model này đạt được perplexity xấp xỉ 27, so với 34 từ các model trước."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Đây là mô hình encoder-decoder được sử dụng từ các notebooks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ![figure1](./images/3.seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ở model trước, chúng ta cùng thiết lập một kiến trúc để giảm việc nén thông tin bằng cách truyền context vector z vào decoder ở mỗi thời điểm. Và, ta truyền cả context vector và embedded input word, $\\bold{d(y_t)}$ cùng với hidden state $s_t$ vào linear layer, f để đưa ra dự đoán."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![figure2](./images/3.seq2seq_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Mặc dù giảm được việc nén thông tin, context vector vẫn phải cần lưu trữ thông tin về source sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Trong notebook này, chúng ta sẽ xây dựng một model xóa bỏ việc đè nén thông tin bằng cách cho phép decoder quan sát toàn bộ source sentence (thông qua các hidden states của nó) ở mỗi bước decoding. Và, chúng ta sẽ sử dụng *attention*. Chi tiết về *attention* sẽ được trình bày ở mục sau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext.legacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c9d8fd26e103>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMulti30k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBucketIterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchtext.legacy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Thiết lập random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load model tokenize tiếng Anh và tiếng Đức của spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tạo tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Field' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-07641b6b0576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m SRC = Field(tokenize = tokenize_de, \n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0minit_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0meos_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             lower = True)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Field' is not defined"
     ]
    }
   ],
   "source": [
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '', \n",
    "            eos_token = '', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '', \n",
    "            eos_token = '', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Build vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Đầu tiên, ta sẽ xây dựng encoder. Tương tự như model ở notebook trước, chúng ta chỉ sư dụng một layer GRU, tuy nhiên bây giờ ta sẽ sử dụng *bidirectional RNN*. Với *bidirectional RNN*, ta có 2 lớp RNNs ở mỗi layer. Quá trình foward của layer RNN đi từ trái sang phải (green), quá trình backward đi từ phải sang trái (teal). Trong pytorch, ta chỉ cần set `bidirectional = True` để sử dụng *bidirectional RNN*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![figure3](./images/3.seq2seq_bidirectional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Giờ đây, chúng ta có: <br> <br>\n",
    "> $\\begin{aligned} h_t^{\\rightarrow} &=\\text { EncoderGRU } \\rightarrow\\left(e\\left(x_t^{\\rightarrow}\\right), h_{t-1}^{\\rightarrow}\\right) \\\\ h_t^{\\leftarrow} &=\\text { EncoderGRU } \\end{aligned}$ <br> <br>\n",
    "> Với $x_0^{\\rightarrow}$ = \\<sos>, $x_1^{\\rightarrow}$ = gutten và $x_0^{\\rightarrow}$ = \\<eos>, $x_1^{\\rightarrow}$ = morgen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Trước đây, chúng ta chỉ truyền 1 đầu vào (`embedded`) vào RNN, và thông báo với Pytorch rằng hãy khởi tạo forward và backward initial hidden states ($h_0^{\\rightarrow}$ và $h_0^{\\leftarrow}$) bằng tensor 0. Sau quá trình xử lý của RNN, ta thu được 2 context vectors, 1 là từ quá trình forward, $z^{\\rightarrow}$ = $h_T^{\\rightarrow}$ và 1 từ quá trình backward, $z^{\\leftarrow}$ = $h_T^{\\leftarrow}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> RNN trả về `outputs` và `hidden`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `outputs` có kích thước **[src len, batch size, hid dim * num directions]**. Phần tử `hid_dim` đầu tiên ở trục thứ 3 là hidden states từ top layer forward RNN, và phần tử `hid_dim` cuối cùng là từ top layer RNN backward. Ta có thể hiểu trục thứ 3 gồm forward và backward hidden states được ghép nối với nhau: $h_1$ = [$h_1^{\\rightarrow}$;$h_T^{\\leftarrow}$], $h_2$ = [$h_2^{\\rightarrow}$;$h_{T-1}^{\\leftarrow}$], ... và, ta ký hiệu tất cả các encoder hidden states (gồm hidden states từ forward và backward được ghép nối với nhau) là H = {$h_1, h_2, h_3, ..., h_T$}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `hidden` có kích thước **[n layers * num directions, batch size, hid dim]**. Sử dụng **[-2,:,:]** cho ta hidden state của top layer forward RNN sau bước cuối cùng và **[-1,:,:]** cho ta hidden state của top layer backward RNN sau bước cuối cùng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decoder là undirectional, nó chỉ cần một context vector z đóng vai trò initial hidden state $s_0$. Mà hiện tại ta đang có 2 context vector ($z^{\\rightarrow}$ = $h_T^{\\rightarrow}$ và $z^{\\leftarrow}$ = $h_T^{\\leftarrow}$). Đơn giản, ta chỉ cần ghép nối 2 vector này lại và cho đi qua một lớp fully connected để giảm về chiều của một vector (ở đây, activation function ta chọn là hàm tanh): <br> \n",
    ">> z = tanh(g($h_T^{\\rightarrow}$, $h_T^{\\leftarrow}$)) = tanh(g($z^{\\rightarrow}$, $z^{\\leftarrow}$)) = $s_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**: Trong paper, người ta chỉ lấy hidden states từ backward RNN và đưa vào linear layer để thu context vector và decoder initial hidden state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Do model chúng ta cần quan sát toàn bộ source sentence nên chúng ta sẽ return `outputs`, stacked forward và backward hidden states của mỗi token trong source sentence. Ngoài ra, ta cần return `hidden` để làm initial hidden state ở decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_dim,\n",
    "                emb_dim,\n",
    "                hid_dim,\n",
    "                n_layers,\n",
    "                dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        if n_layers > 1:\n",
    "            self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout = dropout, bidirectional = True)\n",
    "        else:\n",
    "            self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, bidirectional = True)\n",
    "\n",
    "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src len, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src len, batch size, emb dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs = [src len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        # outputs are always from the last layer\n",
    "\n",
    "        # hidden [-2, :, : ] is the last of the forwards RNN\n",
    "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        # initial decoder hidden is final hidden state of the forwards and backwards\n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        # outputs = [src len, batch size, hid dim * n directions]\n",
    "        # hidden = [batch size, hid dim]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tiếp theo là attention layer. Layer này sẽ nhận đầu vào là previous hidden state của decoder $s_{t-1}$ và tất cả cách stacked foward và backward hidden states từ encoder, **H**. Layer sẽ trả về một attention vector $a_t$ có kích thước là chiều dài của source sentence, mỗi phần tử của vector nằm trong khoảng (0,1) và tổng các phần từ bằng 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bản chất là layer này sẽ lấy đối tượng đã được decode tính tới thời điểm hiện tại $s_{t-1}$ và tất cả những gì chúng ta đã encode, **H** để sinh ra một attention vector $a_t$, vector này biểu diễn việc model nên chú ý tới từ nào trong source sentence để đưa ra dự đoán chính xác cho từ tiếp theo $\\hat{y}_{y+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Đầu tiên, ta tính toán *energy* giữa previous decoder hidden state và encoder hidden states. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "169dd4cfa2618b85e8ef5e64ff9d70433b2e7f87b8c66bdf4b101e8e57acbaaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
